#############################################################
# Confluent Community Platform (single instances)           #
#############################################################
#https://docs.confluent.io/current/installation/docker/image-reference.html
---
version: '2.4'
services:

  #############################################################
  # Apache Zookeeper (CP)                                     #
  #############################################################
  zookeeper:
    image: confluentinc/cp-zookeeper:${VERSION_CONFLUENT}
    hostname: zookeeper
    container_name: zookeeper
    restart: always
    ports:
      - 12181:2181
    # https://docs.confluent.io/current/zookeeper/deployment.html
    # https://docs.confluent.io/current/installation/docker/config-reference.html#zk-configuration
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181 # (required) This is the port where ZooKeeper clients will listen on. This is where the Brokers will connect to ZooKeeper.
      ZOOKEEPER_TICK_TIME: 2000 # (default: 3000) The unit of time for ZooKeeper translated to milliseconds. This governs all ZooKeeper time dependent operations. It is used for heartbeats and timeouts especially.

  #############################################################
  # Confluent Server (CP)                                     #
  #############################################################
  kafka:
    image: confluentinc/cp-server:${VERSION_CONFLUENT}
    hostname: kafka
    container_name: kafka
    restart: always
    ports:
      - 19092:19092
    # https://docs.confluent.io/current/installation/configuration/broker-configs.html
    # https://docs.confluent.io/current/installation/docker/config-reference.html#confluent-kafka-configuration
    environment:
      KAFKA_BROKER_ID: 1 # (default: -1) The broker id for this server. If unset, a unique broker id will be generated.
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181 # (required) Instructs Kafka how to get in touch with ZooKeeper.
      KAFKA_CUB_ZK_TIMEOUT: 60 # (default: 40) Docker image setting, which specified the amount of time to wait for Zookeeper. Could be used, to get rid of Docker healthchecks.
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: DOCKER:PLAINTEXT,HOST:PLAINTEXT # (default: PLAINTEXT:PLAINTEXT,...) Map between listener names and security protocols. In this scenario this setting is used to define listeners with names.
      KAFKA_LISTENERS: DOCKER://:9092,HOST://:19092 # (required) List of URIs we will listen on and the listener names. In this case, Kafka listens in both ports on all interfaces.
      KAFKA_ADVERTISED_LISTENERS: DOCKER://kafka.${DOMAIN_NAME}:9092,HOST://localhost:19092 # (required) Describes how the host name that is advertised and can be reached by clients. HOST://localhost:19092 enables access from Docker host.
      KAFKA_CONTROL_PLAIN_LISTENER_NAME: DOCKER # (default: PLAINTEXT) Name of listener used for communication between controller and brokers. By default, no dedicated listener is used.
      KAFKA_INTER_BROKER_LISTENER_NAME: DOCKER # (default: PLAINTEXT) Name of listener used for communication between brokers.  By default, no dedicated listener is used.
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0 # (default: 3000) The amount of time the group coordinator will wait for more consumers to join a new group before performing the first rebalance. Set to 0 to ensure, that consumers start faster in dev environments.
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false" # (default: true) We disabled auto creation of topics, to ensure that topics are created with the correct configuration. However, if defaults are fine, this could be enabled.
      KAFKA_NUM_PARTITIONS: 3 # (default: 1) The default number of partitions per topic.
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1 # (default: 3) The replication factor for the offsets topic. Must be 1, because we only have a single broker.
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1 # (default: 3) The replication factor for the transaction topic. Must be 1, because we only have a single broker.
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1 # (default: 2) Overridden min.insync.replicas config for the transaction topic. Must be 1, because we only have a single broker.
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1 # (default 3): The replication factor for the license topic. Must be 1, because we only have a single broker.
      KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:8081 # (default: unset) Allows activation of Schema Validation on the brokers for specific topics (see https://docs.confluent.io/current/schema-registry/schema-validation.html)

  #############################################################
  # Confluent Schema Registry (CP)                            #
  #############################################################
  schema-registry:
    image: confluentinc/cp-schema-registry:${VERSION_CONFLUENT}
    hostname: schema-registry
    container_name: schema-registry
    restart: always
    ports:
      - 8081:8081
      - 18081:8081
    # https://docs.confluent.io/current/schema-registry/installation/config.html
    # https://docs.confluent.io/current/installation/docker/config-reference.html#schema-registry-configuration
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry # (required) The advertised host name. Not reuqired in single host mode, but required by the image.
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081 # (default: http://0.0.0.0:8081) Comma-separated list of listeners that listen for API requests
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka:9092 # (required) A list of Kafka brokers to connect. If kafkastore.connection.url is not specified, the Kafka cluster containing these bootstrap servers is used both to coordinate Schema Registry instances (primary election) and to store schema data.
      SCHEMA_REGISTRY_CUB_KAFKA_TIMEOUT: 60 # (default: 40) Docker image setting, which specifies the amount of time to wait for Kafka. Could be used, to get rid of Docker healthchecks.
      SCHEMA_REGISTRY_KAFKASTORE_TOPIC_REPLICATION_FACTOR: 1 # (default: 3) The desired replication factor of the schema topic. Must be 1, because we only have a single broker.
      SCHEMA_REGISTRY_AVRO_COMPATIBILITY_LEVEL: backward # (default: backward) The Avro compatibility type.

  #############################################################
  # Kafka Connect (CP)                                        #
  #############################################################
  connect:
    image: confluentinc/cp-kafka-connect:${VERSION_CONFLUENT}
    hostname: connect
    container_name: connect
    restart: always
    ports:
      - 8083:8083
      - 18083:8083
    # https://docs.confluent.io/current/installation/configuration/connect/index.html
    # https://docs.confluent.io/current/installation/docker/config-reference.html#kafka-connect-configuration
    # https://docs.confluent.io/current/installation/configuration/connect/source-connect-configs.html
    # https://docs.confluent.io/current/installation/configuration/connect/sink-connect-configs.html
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka:9092 # (required) A host:port pair for establishing the initial connection to the Kafka cluster.
      CONNECT_CUB_KAFKA_TIMEOUT: 60 # (default: 40) Docker image setting, which specifies the amount of time to wait for Kafka. Could be used, to get rid of Docker healthchecks.
      CONNECT_REST_ADVERTISED_HOST_NAME: connect # (required) The hostname that is given out to other workers to connect to. Must be resolvable by all containers.
      CONNECT_REST_PORT: 8083 # (default: 8083) Port for the REST API to listen on.
      CONNECT_GROUP_ID: emob_connect # (required) A unique string that identifies the Connect cluster group this worker belongs to.
      CONNECT_CONFIG_STORAGE_TOPIC: emob_connect-configs # (required) The name of the topic in which to store connector and task configuration data. This must be the same for all workers with the same group.id
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1 # (default: 3) Replication factor used when creating the configuration storage topic. Must be 1, because we only have a single broker.
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000 # (default: 60000) Interval at which to try committing offsets for tasks. Explicitly reduced for dev environment.
      CONNECT_OFFSET_STORAGE_TOPIC: emob_connect-offsets # (required) The name of the topic in which to store offset data for connectors. This must be the same for all workers with the same group.id
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1 # (default: 3) Replication factor used when creating the offset storage topic. Must be 1, because we only have a single broker.
      CONNECT_STATUS_STORAGE_TOPIC: emob_connect-status # (required) The name of the topic in which to store state for connectors. This must be the same for all workers with the same group.id
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1 # (default: 3) Replication factor used when creating the status storage topic. Must be 1, because we only have a single broker.
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter # (required) Converter class for keys. This controls the format of the data that will be written to Kafka for source connectors or read from Kafka for sink connectors.
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter # (required) Converter class for values. This controls the format of the data that will be written to Kafka for source connectors or read from Kafka for sink connectors.
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081 # (required) Schema Registry Url which is used by AvroConvertor.
      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter # (required) Converter class for internal keys.
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter # (required) Converter class for internal values.
      CONNECT_PLUGIN_PATH: /usr/share/java,/usr/share/confluent-hub-components,/etc/kafka-connect/jars # (default: /usr/share/java,/usr/share/confluent-hub-components) The plugin.path value that indicates the location from which to load Connect plugins in classloading isolation.
      CLASSPATH: /usr/share/java/kafka/*:/usr/share/java/monitoring-interceptors/* # CLASSPATH required due to CC-2422

  #############################################################
  # Confluent ksqlDB Server                                   #
  #############################################################
  ksqldb-server:
    image: confluentinc/cp-ksqldb-server:${VERSION_CONFLUENT}
    hostname: ksqldb-server
    container_name: ksqldb-server
    restart: always
    ports:
      - 8088:8088
      - 18088:8088
    # https://docs.ksqldb.io/en/latest/operate-and-deploy/installation/server-config/config-reference/
    # https://docs.ksqldb.io/en/latest/operate-and-deploy/installation/install-ksqldb-with-docker/
    environment:
      KSQL_BOOTSTRAP_SERVERS: kafka:9092 # (default: localhost:9092) list of host and port pairs that is used for establishing the initial connection to the Kafka cluster
      KSQL_KSQL_STREAMS_AUTO_OFFSET_RESET: "earliest" # (default: latest) determines what to do when there is no initial offset in Apache Kafka
      KSQL_KSQL_STREAMS_NUM_STREAM_THREADS: 1 # (default: 1) number of stream threads in an instance of the Kafka Streams application
      KSQL_KSQL_STREAMS_PRODUCER_DELIVERY_TIMEOUT_MS: 2147483647 # (default: 120000) Set the batch expiry to Integer.MAX_VALUE to ensure that queries will not terminate if the underlying Kafka cluster is unavailable
      KSQL_KSQL_STREAMS_PRODUCER_MAX_BLOCK_MS: 9223372036854775807 # (default: 60000) Set the maximum allowable time for the producer to block to Long.MAX_VALUE. This allows ksqlDB to pause processing if the underlying Kafka cluster is unavailable.
      KSQL_KSQL_STREAMS_COMMIT_INTERVAL_MS: 2000 # (default: 2000) frequency to save the position of the processor
      KSQL_KSQL_STREAMS_CACHE_MAX_BYTES_BUFFERING: 0 # (default: 10000000) maximum number of memory bytes to be used for buffering across all threads
      KSQL_KSQL_SERVICE_ID: example # (default: default_) used to define the ksqlDB cluster membership of a ksqlDB Server instance
      KSQL_KSQL_OUTPUT_TOPIC_NAME_PREFIX: "" # (default: "") default prefix for automatically created topic names
      KSQL_KSQL_SCHEMA_REGISTRY_URL: http://schema-registry:8081 # (required for Avro) Schema Registry URL path to connect ksqlDB to
      KSQL_LISTENERS: http://0.0.0.0:8088 # (default: http://0.0.0.0:8088) controls the REST API endpoint for the ksqlDB Server
      KSQL_KSQL_STREAMS_STATE_DIR: /tmp/kafka-streams # (default: /tmp/kafka-streams) the storage directory for stateful operations, like aggregations and joins
      KSQL_KSQL_EXTENSION_DIR: /etc/ksql/ext # extension directory for UDFs, see https://docs.ksqldb.io/en/latest/developer-guide/implement-a-udf/
      KSQL_KSQL_CONNECT_URL: http://connect:8083 # The Connect cluster URL to integrate with.
      KSQL_KSQL_CONNECT_POLLING_ENABLE: "true" # Toggles whether or not to poll connect for new connectors and automatically register them in ksqlDB.

networks:
  default:
    name: ${DOMAIN_NAME}
